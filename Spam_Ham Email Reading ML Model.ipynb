{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "109dc4d7",
   "metadata": {},
   "source": [
    "### Aim:\n",
    "To develop a machine learning-based system that can effectively classify email messages as either \"spam\" (unwanted) or \"ham\" (legitimate), using a dataset of labeled emails (spam and ham), in order to enhance email filtering systems and reduce the time and effort spent by users dealing with unwanted emails."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1654bf17",
   "metadata": {},
   "source": [
    "### 1.  Importing Required Libraries and Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1983025",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bbcfa9a",
   "metadata": {},
   "source": [
    "### Loading the csv file into pandas dataframe                                                              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b3740da",
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv(r'D:\\data sets\\spam.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff73b14e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3495</th>\n",
       "      <td>ham</td>\n",
       "      <td>Happy birthday... May u find ur prince charmin...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3496</th>\n",
       "      <td>ham</td>\n",
       "      <td>Oh, the grand is having a bit of a party but i...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3497</th>\n",
       "      <td>ham</td>\n",
       "      <td>You said to me before i went back to bed that ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3498</th>\n",
       "      <td>ham</td>\n",
       "      <td>I hope you arnt pissed off but id would really...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3499</th>\n",
       "      <td>spam</td>\n",
       "      <td>Dorothy@kiefer.com (Bank of Granite issues Str...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3500 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        v1                                                 v2 Unnamed: 2  \\\n",
       "0      ham  Go until jurong point, crazy.. Available only ...        NaN   \n",
       "1      ham                      Ok lar... Joking wif u oni...        NaN   \n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n",
       "3      ham  U dun say so early hor... U c already then say...        NaN   \n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n",
       "...    ...                                                ...        ...   \n",
       "3495   ham  Happy birthday... May u find ur prince charmin...        NaN   \n",
       "3496   ham  Oh, the grand is having a bit of a party but i...        NaN   \n",
       "3497   ham  You said to me before i went back to bed that ...        NaN   \n",
       "3498   ham  I hope you arnt pissed off but id would really...        NaN   \n",
       "3499  spam  Dorothy@kiefer.com (Bank of Granite issues Str...        NaN   \n",
       "\n",
       "     Unnamed: 3 Unnamed: 4  \n",
       "0           NaN        NaN  \n",
       "1           NaN        NaN  \n",
       "2           NaN        NaN  \n",
       "3           NaN        NaN  \n",
       "4           NaN        NaN  \n",
       "...         ...        ...  \n",
       "3495        NaN        NaN  \n",
       "3496        NaN        NaN  \n",
       "3497        NaN        NaN  \n",
       "3498        NaN        NaN  \n",
       "3499        NaN        NaN  \n",
       "\n",
       "[3500 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a212bbc",
   "metadata": {},
   "source": [
    "### Data Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "154f9e69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3500 entries, 0 to 3499\n",
      "Data columns (total 5 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   v1          3500 non-null   object\n",
      " 1   v2          3500 non-null   object\n",
      " 2   Unnamed: 2  28 non-null     object\n",
      " 3   Unnamed: 3  7 non-null      object\n",
      " 4   Unnamed: 4  3 non-null      object\n",
      "dtypes: object(5)\n",
      "memory usage: 136.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53ee9db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'v1': 'spam_ham', 'v2': 'email'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65b76a26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     spam_ham                                              email Unnamed: 2  \\\n",
      "0         ham  Go until jurong point crazy Available only in ...        NaN   \n",
      "1         ham                            Ok lar Joking wif u oni        NaN   \n",
      "2        spam  Free entry in a wkly comp to win FA Cup final ...        NaN   \n",
      "3         ham        U dun say so early hor U c already then say        NaN   \n",
      "4         ham  Nah I dont think he goes to usf he lives aroun...        NaN   \n",
      "...       ...                                                ...        ...   \n",
      "3495      ham  Happy birthday May u find ur prince charming s...        NaN   \n",
      "3496      ham  Oh the grand is having a bit of a party but it...        NaN   \n",
      "3497      ham  You said to me before i went back to bed that ...        NaN   \n",
      "3498      ham  I hope you arnt pissed off but id would really...        NaN   \n",
      "3499     spam  Dorothykiefercom Bank of Granite issues Strong...        NaN   \n",
      "\n",
      "     Unnamed: 3 Unnamed: 4  \n",
      "0           NaN        NaN  \n",
      "1           NaN        NaN  \n",
      "2           NaN        NaN  \n",
      "3           NaN        NaN  \n",
      "4           NaN        NaN  \n",
      "...         ...        ...  \n",
      "3495        NaN        NaN  \n",
      "3496        NaN        NaN  \n",
      "3497        NaN        NaN  \n",
      "3498        NaN        NaN  \n",
      "3499        NaN        NaN  \n",
      "\n",
      "[3500 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'[^a-zA-Z\\s]','',text)\n",
    "    text = re.sub(r'\\s+',' ',text)\n",
    "    return text.strip()\n",
    "df['spam_ham'] = df['spam_ham'].apply(clean_text)\n",
    "df['email'] = df['email'].apply(clean_text)\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aaefb73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['Unnamed: 2','Unnamed: 3','Unnamed: 4'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57f829c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spam_ham</th>\n",
       "      <th>email</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point crazy Available only in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar Joking wif u oni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in a wkly comp to win FA Cup final ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor U c already then say</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I dont think he goes to usf he lives aroun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3495</th>\n",
       "      <td>ham</td>\n",
       "      <td>Happy birthday May u find ur prince charming s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3496</th>\n",
       "      <td>ham</td>\n",
       "      <td>Oh the grand is having a bit of a party but it...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3497</th>\n",
       "      <td>ham</td>\n",
       "      <td>You said to me before i went back to bed that ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3498</th>\n",
       "      <td>ham</td>\n",
       "      <td>I hope you arnt pissed off but id would really...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3499</th>\n",
       "      <td>spam</td>\n",
       "      <td>Dorothykiefercom Bank of Granite issues Strong...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3500 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     spam_ham                                              email\n",
       "0         ham  Go until jurong point crazy Available only in ...\n",
       "1         ham                            Ok lar Joking wif u oni\n",
       "2        spam  Free entry in a wkly comp to win FA Cup final ...\n",
       "3         ham        U dun say so early hor U c already then say\n",
       "4         ham  Nah I dont think he goes to usf he lives aroun...\n",
       "...       ...                                                ...\n",
       "3495      ham  Happy birthday May u find ur prince charming s...\n",
       "3496      ham  Oh the grand is having a bit of a party but it...\n",
       "3497      ham  You said to me before i went back to bed that ...\n",
       "3498      ham  I hope you arnt pissed off but id would really...\n",
       "3499     spam  Dorothykiefercom Bank of Granite issues Strong...\n",
       "\n",
       "[3500 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "33ea50f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "32268c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Convert all text to lowercase to maintain uniformity.\n",
    "df['email'] = df['email'].str.lower()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2e9a8e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenization: Split the text into words or tokens.\n",
    "\n",
    "df['email'] = df['email'].apply(nltk.word_tokenize)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c0fd1c11",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading stop_words: Package 'stop_words' not found\n",
      "[nltk_data]     in index\n"
     ]
    }
   ],
   "source": [
    "#Removing Stopwords: Filter out common stopwords that may not add much meaning.\n",
    "nltk.download('stop_words')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "df['email'] =df['email'].apply(lambda x :[word for word in x if word not in stop_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "732d8b5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\deshp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "df['email'] = df['email'].apply(lambda x: [lemmatizer.lemmatize(word) for word in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "34502e0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spam_ham</th>\n",
       "      <th>email</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>[go, jurong, point, crazy, available, bugis, n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>[ok, lar, joking, wif, u, oni]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>[free, entry, wkly, comp, win, fa, cup, final,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>[u, dun, say, early, hor, u, c, already, say]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>[nah, dont, think, go, usf, life, around, though]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3495</th>\n",
       "      <td>ham</td>\n",
       "      <td>[happy, birthday, may, u, find, ur, prince, ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3496</th>\n",
       "      <td>ham</td>\n",
       "      <td>[oh, grand, bit, party, doesnt, mention, cover...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3497</th>\n",
       "      <td>ham</td>\n",
       "      <td>[said, went, back, bed, cant, sleep, anything]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3498</th>\n",
       "      <td>ham</td>\n",
       "      <td>[hope, arnt, pissed, id, would, really, like, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3499</th>\n",
       "      <td>spam</td>\n",
       "      <td>[dorothykiefercom, bank, granite, issue, stron...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3500 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     spam_ham                                              email\n",
       "0         ham  [go, jurong, point, crazy, available, bugis, n...\n",
       "1         ham                     [ok, lar, joking, wif, u, oni]\n",
       "2        spam  [free, entry, wkly, comp, win, fa, cup, final,...\n",
       "3         ham      [u, dun, say, early, hor, u, c, already, say]\n",
       "4         ham  [nah, dont, think, go, usf, life, around, though]\n",
       "...       ...                                                ...\n",
       "3495      ham  [happy, birthday, may, u, find, ur, prince, ch...\n",
       "3496      ham  [oh, grand, bit, party, doesnt, mention, cover...\n",
       "3497      ham     [said, went, back, bed, cant, sleep, anything]\n",
       "3498      ham  [hope, arnt, pissed, id, would, really, like, ...\n",
       "3499     spam  [dorothykiefercom, bank, granite, issue, stron...\n",
       "\n",
       "[3500 rows x 2 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "75bc459a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spam_ham</th>\n",
       "      <th>email</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>go jurong point crazy available bugis n great ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>ok lar joking wif u oni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>free entry wkly comp win fa cup final tkts st ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>u dun say early hor u c already say</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>nah dont think go usf life around though</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3495</th>\n",
       "      <td>ham</td>\n",
       "      <td>happy birthday may u find ur prince charming s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3496</th>\n",
       "      <td>ham</td>\n",
       "      <td>oh grand bit party doesnt mention cover charge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3497</th>\n",
       "      <td>ham</td>\n",
       "      <td>said went back bed cant sleep anything</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3498</th>\n",
       "      <td>ham</td>\n",
       "      <td>hope arnt pissed id would really like see tomo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3499</th>\n",
       "      <td>spam</td>\n",
       "      <td>dorothykiefercom bank granite issue strongbuy ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3500 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     spam_ham                                              email\n",
       "0         ham  go jurong point crazy available bugis n great ...\n",
       "1         ham                            ok lar joking wif u oni\n",
       "2        spam  free entry wkly comp win fa cup final tkts st ...\n",
       "3         ham                u dun say early hor u c already say\n",
       "4         ham           nah dont think go usf life around though\n",
       "...       ...                                                ...\n",
       "3495      ham  happy birthday may u find ur prince charming s...\n",
       "3496      ham  oh grand bit party doesnt mention cover charge...\n",
       "3497      ham             said went back bed cant sleep anything\n",
       "3498      ham  hope arnt pissed id would really like see tomo...\n",
       "3499     spam  dorothykiefercom bank granite issue strongbuy ...\n",
       "\n",
       "[3500 rows x 2 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f44173",
   "metadata": {},
   "source": [
    "### Splitting data in to x y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "32cf2030",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.iloc[:,-1].values\n",
    "y = df.iloc[:,:-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "10a8e848",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([list([101, 101, 2175, 18414, 17583, 2391, 4689, 2800, 11829, 2483, 1050, 2307, 2088, 2474, 1041, 28305, 25022, 2638, 2288, 26297, 28194, 102, 102]),\n",
       "       list([101, 101, 7929, 2474, 2099, 16644, 15536, 2546, 1057, 2006, 2072, 102, 102]),\n",
       "       list([101, 101, 2489, 4443, 1059, 2243, 2135, 4012, 2361, 2663, 6904, 2452, 2345, 1056, 25509, 2015, 2358, 2089, 3793, 6904, 4374, 4443, 3980, 2102, 2094, 19067, 2102, 3446, 13535, 2015, 6611, 2058, 102, 102]),\n",
       "       ...,\n",
       "       list([101, 101, 2056, 2253, 2067, 2793, 2064, 2102, 3637, 2505, 102, 102]),\n",
       "       list([101, 101, 3246, 12098, 3372, 9421, 8909, 2052, 2428, 2066, 2156, 4826, 2293, 22038, 20348, 20348, 20348, 20348, 20348, 20348, 102, 102]),\n",
       "       list([101, 101, 9984, 11602, 7512, 9006, 2924, 9753, 3277, 2844, 8569, 2100, 11355, 4060, 2266, 17235, 2850, 4160, 6454, 3729, 13512, 2566, 102, 102])],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "276f19bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['ham'],\n",
       "       ['ham'],\n",
       "       ['spam'],\n",
       "       ...,\n",
       "       ['ham'],\n",
       "       ['ham'],\n",
       "       ['spam']], dtype=object)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "586c4014",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spam_ham    0\n",
       "email       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b5cfb2",
   "metadata": {},
   "source": [
    "###  Data Encoding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4c3ddfed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\deshp\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:115: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3cb95a22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3500"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "17c299d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, ..., 0, 0, 1])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed73122",
   "metadata": {},
   "source": [
    " ### Vectorization TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2412530a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = vectorizer.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "17642991",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3500x6088 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 28503 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8185aab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BERT\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "df['email'] = df['email'].apply(lambda x: tokenizer.encode(x, add_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33737b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.iloc[:,-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8004d20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the data into test and train sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(tfidf_matrix, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e3122a4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2800x6088 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 22954 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb29171",
   "metadata": {},
   "source": [
    "### Training the Model using  SVC  Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8a28f055",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(kernel='linear', random_state=0)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "classifier = SVC(kernel = 'linear', random_state = 0)\n",
    "classifier.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7ea09906",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e1e87ffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " ...\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]]\n"
     ]
    }
   ],
   "source": [
    "print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "337714cf",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5ffe23ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[613   1]\n",
      " [ 15  71]]\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score\n",
    "cm = confusion_matrix(y_test,y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3d4d1f",
   "metadata": {},
   "source": [
    "### Accuracy score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "10aed040",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9771428571428571"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cbdbdc4",
   "metadata": {},
   "source": [
    "### Conclusion: The project aims to create a robust spam filtering system that enhances email security, boosts user productivity, and reduces exposure to malicious content. With an accuracy of 97%, the model effectively classifies email messages as spam or ham, ensuring a high level of reliability in filtering out unwanted emails while preserving legitimate communications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b514ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1616627f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a0c427",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d1ce03",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
